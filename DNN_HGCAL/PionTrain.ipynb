{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "excellent-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "\n",
    "from PionModel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ready-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model.\n",
    "# This can be used to train a new weights set, or can evaluate data sets using existing weight sets. \n",
    "# Imported from PionModel\n",
    "net = NN()\n",
    "# Set the Criterion and optimizer for training later\n",
    "criterion = MARE\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "connected-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data for the summed energy layers to be used as input for the NN\n",
    "# and targets as the training comparison values.\n",
    "#import flat distribution training set for pion\n",
    "with open('/home/rusack/shared/pickles/HGCAL_TestBeam/pkl_files/DiscreteSim_pklFiles_Jul22/v1/FTFP_pklFiles/trueE_target.pickle', 'rb') as f:\n",
    "    targets = pickle.load(f)\n",
    "    \n",
    "#energy of each layer summed up.\n",
    "with open(f'/home/rusack/shared/pickles/HGCAL_TestBeam/pkl_files/DiscreteSim_pklFiles_Jul22/v1/FTFP_pklFiles/layer_energy_sum.pickle', 'rb') as a4:\n",
    "    layerSum = pickle.load(a4)\n",
    "\n",
    "# with open(f'/home/rusack/shared/pickles/HGCAL_TestBeam/pkl_files/DiscreteSim_pklFiles_Jul22/v1/FTFP_pklFiles/Hit_Z.pickle', 'rb') as a1:\n",
    "#     layers = pickle.load(a1)\n",
    "# with open(f'/home/rusack/shared/pickles/HGCAL_TestBeam/pkl_files/DiscreteSim_pklFiles_Jul22/v1/FTFP_pklFiles/recHitEn.pickle', 'rb') as a2:\n",
    "#     energy = pickle.load(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sized-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Seperates the individual hits in the detector by their corresponding layers and sums them\n",
    "# layer_position = np.unique(ak.flatten(layers))[0:50]\n",
    "# temp = [ ak.sum(energy[layers==lz], axis=1) for lz in layer_position ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the layer_sum data 80:20 into a training set and a testing set.\n",
    "\n",
    "layerSum = np.array(layerSum)\n",
    "\n",
    "# number of events used for training, should be all events unless troubleshooting\n",
    "num_selected = len(layerSum)\n",
    "\n",
    "split = 0.8\n",
    "\n",
    "xfull = np.asarray(layerSum)\n",
    "xtrain = xfull[:int(np.floor(num_selected*split)),:]\n",
    "xtrain = torch.Tensor(xtrain)\n",
    "xtest = xfull[int(np.floor(num_selected*split)):num_selected,:]\n",
    "xtest = torch.Tensor(xtest)\n",
    "\n",
    "yfull = np.asarray(targets)\n",
    "ytrain = yfull[:int(np.floor(num_selected*split))]\n",
    "ytrain = torch.Tensor(ytrain)\n",
    "ytrain = ytrain.unsqueeze(-1)\n",
    "ytest = yfull[int(np.floor(num_selected*split)):num_selected]\n",
    "ytest = torch.Tensor(ytest)\n",
    "ytest = ytest.unsqueeze(-1)\n",
    "\n",
    "\n",
    "# print(\"layerSum \", np.shape(layerSum))\n",
    "# print(\"xtrain \", np.shape(xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters and the training loop.\n",
    "# The loop takes random permutations of the training or testing loop such that the ordering\n",
    "# does not affect the predictions. \n",
    "# The loss batch in the testing and training are stored for each epoch.\n",
    "# Epoch num arbitrarily chosen to show that it adequately trains after only a few epochs.\n",
    "batch_size = 256*2\n",
    "EPOCHS = 100\n",
    "epoch_loss = []\n",
    "epoch_loss_test = []\n",
    "total_loss = []\n",
    "for epoch in range(EPOCHS):\n",
    "    #set to training mode (can alter the weights)\n",
    "    net.train()\n",
    "    batch_loss = []\n",
    "    \n",
    "    #create permutation\n",
    "    permutation = torch.randperm(xtrain.size()[0])\n",
    "    for i in range(0,xtrain.size()[0],batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = xtrain[indices,:], ytrain[indices]\n",
    "        # Train on a batch permutation \n",
    "        loss, output = train(net, batch_x, batch_y, optimizer, criterion)\n",
    "        batch_loss.append(torch.detach(loss).numpy())\n",
    "#         total_loss.append(torch.detach(loss).numpy())\n",
    "    epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "    \n",
    "    \n",
    "    # Set to evaluation mode (does not update weights)\n",
    "    net.eval()\n",
    "    batch_lt = []\n",
    "    permutation = torch.randperm(xtest.size()[0])\n",
    "    for i in range(0,xtest.size()[0],batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = xtest[indices,:], ytest[indices]\n",
    "        # Test on a batch permutation\n",
    "        loss, output = train(net, batch_x, batch_y, optimizer, criterion)\n",
    "        batch_lt.append(torch.detach(loss).numpy())\n",
    "    epoch_loss_test.append(sum(batch_lt)/len(batch_lt))\n",
    "    torch.save(net.state_dict(), f'PionDNNstates/exampleRun/epoch{epoch}')\n",
    "    \n",
    "# Format loss arrays for plotting\n",
    "epoch_loss = np.asarray(epoch_loss)\n",
    "epoch_loss = epoch_loss.flatten()\n",
    "epoch_loss_test = np.asarray(epoch_loss_test)\n",
    "epoch_loss_test = epoch_loss_test.flatten()\n",
    "torch.save(net.state_dict(), 'PionDNNstates/exampleRun/epochfinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"PionDNNstates/exampleRun/epoch_loss.csv\", epoch_loss, delimiter=\",\")\n",
    "# np.savetxt(\"PionDNNstates/exampleRun/epoch_loss_test.csv\", epoch_loss_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(epoch_loss, c='red', label='training set')\n",
    "plt.plot(epoch_loss_test, c='blue', label='testing set')\n",
    "plt.ylabel('Loss', size=14)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend(fontsize=12, loc='upper right')\n",
    "plt.title('Pion DNN total loss per epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot epoch loss for training and testing\n",
    "\n",
    "fig2 = go.Figure(go.Scatter(dict(y=epoch_loss, name='Epoch Loss Training')))\n",
    "fig2.update_layout(\n",
    "    title = f\"MARE Loss over {EPOCHS} epochs\",\n",
    "    xaxis_title=\"Epoch\",\n",
    "    yaxis_title=\"Loss\",\n",
    "    xaxis=dict(tickformat=',d'),\n",
    "    yaxis=dict(type='log')\n",
    ")\n",
    "fig2.add_trace(go.Scatter(y=epoch_loss_test, name='Epoch Loss Testing', mode='lines'))\n",
    "\n",
    "fig4 = go.Figure(go.Scatter(dict(y=epoch_loss, name='Epoch Loss Training')))\n",
    "fig4.update_layout(\n",
    "    title = f\"MARE Loss over {EPOCHS} epochs\",\n",
    "    xaxis_title=\"Epoch\",\n",
    "    yaxis_title=\"Loss\",\n",
    "    xaxis=dict(tickformat=',d', ),\n",
    "    yaxis_range=[-0.05,1.05]\n",
    ")\n",
    "fig4.add_trace(go.Scatter(y=epoch_loss_test, name='Epoch Loss Testing', mode='lines'))\n",
    "\n",
    "fig2.show()\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-cycling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
